{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohan-gt/machine-learning-from-scratch/blob/master/Natural%20Language%20Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLIS6vwqPvDN"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "NLTK is used mainly used be researchers while SpaCy is used by app developers. SpaCy is faster than NLTK but uses more memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YMM-LnLAfE5"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZtpjby9ALLA",
        "outputId": "3ac88c2f-8418-480c-8ad7-368a8138869b"
      },
      "source": [
        "#!pip install modin[all]\n",
        "\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bomaomQlG6qT"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfd0ifQ0WNxb",
        "outputId": "19c615c8-aaaf-4c39-bbae-4e5516271561"
      },
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "\n",
        "# Initialize corpus\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "\n",
        "# Get train filepaths\n",
        "path = 'aclImdb/train/neg/'\n",
        "filepaths = [path + filepath for filepath in os.listdir(path)]\n",
        "path = 'aclImdb/train/pos/'\n",
        "filepaths.extend([path + filepath for filepath in os.listdir(path)])\n",
        "\n",
        "# Populate train corpus\n",
        "for filepath in filepaths:\n",
        "    with open(filepath, 'r') as fp:\n",
        "        df_train.loc[filepaths.index(filepath), 'Id'] = re.split('/|_|\\.', filepath)[4]\n",
        "        df_train.loc[filepaths.index(filepath), 'Review'] = fp.read()\n",
        "        df_train.loc[filepaths.index(filepath), 'Rating'] = re.split('/|_|\\.', filepath)[5]\n",
        "        df_train.loc[filepaths.index(filepath), 'Sentiment'] = 0 if 'neg' in filepath else 1\n",
        "\n",
        "# Get test filepaths\n",
        "path = 'aclImdb/test/neg/'\n",
        "filepaths = [path + filepath for filepath in os.listdir(path)]\n",
        "path = 'aclImdb/test/pos/'\n",
        "filepaths.extend([path + filepath for filepath in os.listdir(path)])\n",
        "\n",
        "# Populate test corpus\n",
        "for filepath in filepaths:\n",
        "    with open(filepath, 'r') as fp:\n",
        "        df_test.loc[filepaths.index(filepath), 'Id'] = re.split('/|_|\\.', filepath)[4]\n",
        "        df_test.loc[filepaths.index(filepath), 'Review'] = fp.read()\n",
        "        df_test.loc[filepaths.index(filepath), 'Rating'] = re.split('/|_|\\.', filepath)[5]\n",
        "        df_test.loc[filepaths.index(filepath), 'Sentiment'] = 0 if 'neg' in filepath else 1\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-22 19:53:15--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  23.1MB/s    in 4.5s    \n",
            "\n",
            "2021-01-22 19:53:19 (18.0 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp6RVjorKEMs"
      },
      "source": [
        "## Initialize variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYMueZDLKGbK"
      },
      "source": [
        "spacy_nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-vWh-2U5YwD"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_XuDFJ3Ih7r"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhOTLdTLIlPB"
      },
      "source": [
        "#### Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlz6rObxKM4Z"
      },
      "source": [
        "##### NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCcnlOqSIm22"
      },
      "source": [
        "word_tokenize(data)[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "141-kKVZKQFo"
      },
      "source": [
        "##### SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_OPUJl1KSL0"
      },
      "source": [
        "tokens = [token.text for token in spacy_data]\n",
        "tokens[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wMQ_yt4I2J2"
      },
      "source": [
        "#### Sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR6SZJMXKVsE"
      },
      "source": [
        "##### NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjyMNwAQI4PG"
      },
      "source": [
        "sent_tokenize(data)[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jVzyNcNKW0X"
      },
      "source": [
        "##### SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8nHvYcRKYZi"
      },
      "source": [
        "spacy_data = spacy_nlp(df_train['Review'][0])\n",
        "tokens = [str(token) for token in spacy_data.sents]\n",
        "tokens[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqd-s43mpkAj"
      },
      "source": [
        "### Remove Stop Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8cOg4mgpzGP"
      },
      "source": [
        "### N-Gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkhA-ridQVge"
      },
      "source": [
        "### Document-Term Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpMwmnXLQX1S"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform([data]).toarray()\n",
        "columns = vectorizer.get_feature_names()\n",
        "\n",
        "df_dtm = pd.DataFrame(X, columns=columns)\n",
        "df_dtm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXqq0xvBps8b"
      },
      "source": [
        "## Parts of Speech (POS) Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dONIsBavpnmV"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZe1NZcxprA6"
      },
      "source": [
        "## Topic Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmpGIECTqUns"
      },
      "source": [
        "### Term Frequency Inverse Document Frequency (TF-IDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUJhdtSWqWq2"
      },
      "source": [
        "### Latent Dirichlet Allocation (LDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXO61NTQqhgz"
      },
      "source": [
        "### Latent Symantic Indexing (LSI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4TJarQhql4L"
      },
      "source": [
        "### Negative Matrix Factorization (NMF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U79Z1cB033Az"
      },
      "source": [
        "## Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEOueG-N36QT"
      },
      "source": [
        "### Markov Chains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etIKMc9x35m6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}